[cloudera@quickstart retail]$ spark-submit --master yarn --conf spark.ui.port=4043 --num-executors 2 --executor-memory 512M src/main/python/DailyRevenuePerProduct.py
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/zookeeper/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/flume-ng/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/parquet/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/avro/avro-tools-1.7.6-cdh5.13.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/03/13 08:28:14 INFO spark.SparkContext: Running Spark version 1.6.0
20/03/13 08:28:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/03/13 08:28:16 WARN util.Utils: Your hostname, quickstart.cloudera resolves to a loopback address: 127.0.0.1; using 192.168.222.178 instead (on interface eth1)
20/03/13 08:28:16 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address
20/03/13 08:28:16 INFO spark.SecurityManager: Changing view acls to: cloudera
20/03/13 08:28:16 INFO spark.SecurityManager: Changing modify acls to: cloudera
20/03/13 08:28:16 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(cloudera); users with modify permissions: Set(cloudera)
20/03/13 08:28:17 INFO util.Utils: Successfully started service 'sparkDriver' on port 36175.
20/03/13 08:28:17 INFO slf4j.Slf4jLogger: Slf4jLogger started
20/03/13 08:28:18 INFO Remoting: Starting remoting
20/03/13 08:28:18 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.222.178:54606]
20/03/13 08:28:19 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@192.168.222.178:54606]
20/03/13 08:28:19 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 54606.
20/03/13 08:28:19 INFO spark.SparkEnv: Registering MapOutputTracker
20/03/13 08:28:19 INFO spark.SparkEnv: Registering BlockManagerMaster
20/03/13 08:28:19 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-5d8ee3ce-4fe3-49f0-9373-cf0d407fb910
20/03/13 08:28:19 INFO storage.MemoryStore: MemoryStore started with capacity 534.5 MB
20/03/13 08:28:20 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/03/13 08:28:21 INFO server.Server: jetty-8.y.z-SNAPSHOT
20/03/13 08:28:21 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4043
20/03/13 08:28:21 INFO util.Utils: Successfully started service 'SparkUI' on port 4043.
20/03/13 08:28:21 INFO ui.SparkUI: Started SparkUI at http://192.168.222.178:4043
20/03/13 08:28:22 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
20/03/13 08:28:22 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers
20/03/13 08:28:23 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
20/03/13 08:28:23 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/03/13 08:28:23 INFO yarn.Client: Setting up container launch context for our AM
20/03/13 08:28:23 INFO yarn.Client: Setting up the launch environment for our AM container
20/03/13 08:28:23 INFO yarn.Client: Preparing resources for our AM container
20/03/13 08:28:25 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
20/03/13 08:28:25 INFO yarn.Client: Uploading resource file:/usr/lib/spark/lib/spark-assembly-1.6.0-cdh5.13.0-hadoop2.6.0-cdh5.13.0.jar -> hdfs://quickstart.cloudera:8020/user/cloudera/.sparkStaging/application_1581487397453_0111/spark-assembly-1.6.0-cdh5.13.0-hadoop2.6.0-cdh5.13.0.jar
20/03/13 08:28:27 INFO yarn.Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://quickstart.cloudera:8020/user/cloudera/.sparkStaging/application_1581487397453_0111/pyspark.zip
20/03/13 08:28:27 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1281)
	at java.lang.Thread.join(Thread.java:1355)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:967)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:705)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:894)
20/03/13 08:28:27 INFO yarn.Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.9-src.zip -> hdfs://quickstart.cloudera:8020/user/cloudera/.sparkStaging/application_1581487397453_0111/py4j-0.9-src.zip
20/03/13 08:28:27 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1281)
	at java.lang.Thread.join(Thread.java:1355)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:967)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:705)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:894)
20/03/13 08:28:27 INFO yarn.Client: Uploading resource file:/tmp/spark-426a3a48-f98c-4ebf-bef7-23d6ae913673/__spark_conf__5485126579808001622.zip -> hdfs://quickstart.cloudera:8020/user/cloudera/.sparkStaging/application_1581487397453_0111/__spark_conf__5485126579808001622.zip
20/03/13 08:28:27 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1281)
	at java.lang.Thread.join(Thread.java:1355)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:967)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:705)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:894)
20/03/13 08:28:28 INFO spark.SecurityManager: Changing view acls to: cloudera
20/03/13 08:28:28 INFO spark.SecurityManager: Changing modify acls to: cloudera
20/03/13 08:28:28 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(cloudera); users with modify permissions: Set(cloudera)
20/03/13 08:28:28 INFO yarn.Client: Submitting application 111 to ResourceManager
20/03/13 08:28:28 INFO impl.YarnClientImpl: Submitted application application_1581487397453_0111
20/03/13 08:28:29 INFO yarn.Client: Application report for application_1581487397453_0111 (state: ACCEPTED)
20/03/13 08:28:29 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: root.cloudera
	 start time: 1584068308101
	 final status: UNDEFINED
	 tracking URL: http://quickstart.cloudera:8088/proxy/application_1581487397453_0111/
	 user: cloudera
20/03/13 08:28:30 INFO yarn.Client: Application report for application_1581487397453_0111 (state: ACCEPTED)
20/03/13 08:28:31 INFO yarn.Client: Application report for application_1581487397453_0111 (state: ACCEPTED)
20/03/13 08:28:32 INFO yarn.Client: Application report for application_1581487397453_0111 (state: ACCEPTED)
20/03/13 08:28:33 INFO yarn.Client: Application report for application_1581487397453_0111 (state: ACCEPTED)
20/03/13 08:28:34 INFO yarn.Client: Application report for application_1581487397453_0111 (state: ACCEPTED)
20/03/13 08:28:35 INFO yarn.Client: Application report for application_1581487397453_0111 (state: ACCEPTED)
20/03/13 08:28:36 INFO yarn.Client: Application report for application_1581487397453_0111 (state: ACCEPTED)
20/03/13 08:28:37 INFO yarn.Client: Application report for application_1581487397453_0111 (state: ACCEPTED)
20/03/13 08:28:38 INFO yarn.Client: Application report for application_1581487397453_0111 (state: ACCEPTED)
20/03/13 08:28:38 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null)
20/03/13 08:28:38 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> quickstart.cloudera, PROXY_URI_BASES -> http://quickstart.cloudera:8088/proxy/application_1581487397453_0111), /proxy/application_1581487397453_0111
20/03/13 08:28:38 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
20/03/13 08:28:39 INFO yarn.Client: Application report for application_1581487397453_0111 (state: ACCEPTED)
20/03/13 08:28:40 INFO yarn.Client: Application report for application_1581487397453_0111 (state: RUNNING)
20/03/13 08:28:40 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 192.168.222.178
	 ApplicationMaster RPC port: 0
	 queue: root.cloudera
	 start time: 1584068308101
	 final status: UNDEFINED
	 tracking URL: http://quickstart.cloudera:8088/proxy/application_1581487397453_0111/
	 user: cloudera
20/03/13 08:28:40 INFO cluster.YarnClientSchedulerBackend: Application application_1581487397453_0111 has started running.
20/03/13 08:28:40 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58973.
20/03/13 08:28:40 INFO netty.NettyBlockTransferService: Server created on 58973
20/03/13 08:28:40 INFO storage.BlockManagerMaster: Trying to register BlockManager
20/03/13 08:28:40 INFO storage.BlockManagerMasterEndpoint: Registering block manager 192.168.222.178:58973 with 534.5 MB RAM, BlockManagerId(driver, 192.168.222.178, 58973)
20/03/13 08:28:40 INFO storage.BlockManagerMaster: Registered BlockManager
20/03/13 08:28:51 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)
20/03/13 08:28:58 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (192.168.222.178:34179) with ID 1
20/03/13 08:28:59 INFO storage.BlockManagerMasterEndpoint: Registering block manager 192.168.222.178:46321 with 267.3 MB RAM, BlockManagerId(1, 192.168.222.178, 46321)
20/03/13 08:28:59 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 203.2 KB, free 534.3 MB)
20/03/13 08:29:00 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.6 KB, free 534.3 MB)
20/03/13 08:29:00 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.222.178:58973 (size: 24.6 KB, free: 534.5 MB)
20/03/13 08:29:00 INFO spark.SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2
20/03/13 08:29:00 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 207.4 KB, free 534.1 MB)
20/03/13 08:29:01 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.6 KB, free 534.1 MB)
20/03/13 08:29:01 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.222.178:58973 (size: 24.6 KB, free: 534.5 MB)
20/03/13 08:29:01 INFO spark.SparkContext: Created broadcast 1 from textFile at NativeMethodAccessorImpl.java:-2
20/03/13 08:29:02 INFO mapred.FileInputFormat: Total input paths to process : 1
20/03/13 08:29:03 INFO mapred.FileInputFormat: Total input paths to process : 1
20/03/13 08:29:04 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
20/03/13 08:29:04 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
20/03/13 08:29:04 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
20/03/13 08:29:04 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
20/03/13 08:29:04 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
20/03/13 08:29:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/03/13 08:29:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/03/13 08:29:04 INFO spark.SparkContext: Starting job: saveAsTextFile at NativeMethodAccessorImpl.java:-2
20/03/13 08:29:04 INFO scheduler.DAGScheduler: Registering RDD 8 (join at /home/cloudera/pythondemo/retail/src/main/python/DailyRevenuePerProduct.py:14)
20/03/13 08:29:04 INFO scheduler.DAGScheduler: Registering RDD 12 (reduceByKey at /home/cloudera/pythondemo/retail/src/main/python/DailyRevenuePerProduct.py:17)
20/03/13 08:29:05 INFO scheduler.DAGScheduler: Registering RDD 20 (join at /home/cloudera/pythondemo/retail/src/main/python/DailyRevenuePerProduct.py:24)
20/03/13 08:29:05 INFO scheduler.DAGScheduler: Got job 0 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) with 1 output partitions
20/03/13 08:29:05 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (saveAsTextFile at NativeMethodAccessorImpl.java:-2)
20/03/13 08:29:05 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
20/03/13 08:29:05 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 2)
20/03/13 08:29:05 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[8] at join at /home/cloudera/pythondemo/retail/src/main/python/DailyRevenuePerProduct.py:14), which has no missing parents
20/03/13 08:29:05 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.1 KB, free 534.1 MB)
20/03/13 08:29:05 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.8 KB, free 534.1 MB)
20/03/13 08:29:05 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.222.178:58973 (size: 6.8 KB, free: 534.5 MB)
20/03/13 08:29:05 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004
20/03/13 08:29:05 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 0 (PairwiseRDD[8] at join at /home/cloudera/pythondemo/retail/src/main/python/DailyRevenuePerProduct.py:14) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/03/13 08:29:05 INFO cluster.YarnScheduler: Adding task set 0.0 with 4 tasks
20/03/13 08:29:05 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.222.178, executor 1, partition 0, RACK_LOCAL, 2270 bytes)
20/03/13 08:29:07 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.222.178:46321 (size: 6.8 KB, free: 267.3 MB)
20/03/13 08:29:08 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (192.168.222.178:34183) with ID 2
20/03/13 08:29:08 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 192.168.222.178, executor 2, partition 1, RACK_LOCAL, 2270 bytes)
20/03/13 08:29:08 INFO storage.BlockManagerMasterEndpoint: Registering block manager 192.168.222.178:36056 with 267.3 MB RAM, BlockManagerId(2, 192.168.222.178, 36056)
20/03/13 08:29:08 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.222.178:46321 (size: 24.6 KB, free: 267.2 MB)
20/03/13 08:29:09 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.222.178:36056 (size: 6.8 KB, free: 267.3 MB)
20/03/13 08:29:10 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.222.178:36056 (size: 24.6 KB, free: 267.2 MB)
20/03/13 08:29:19 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 192.168.222.178, executor 1, partition 2, RACK_LOCAL, 2275 bytes)
20/03/13 08:29:19 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 13943 ms on 192.168.222.178 (executor 1) (1/4)
20/03/13 08:29:19 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.222.178:46321 (size: 24.6 KB, free: 267.2 MB)
20/03/13 08:29:20 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 192.168.222.178, executor 2, partition 3, RACK_LOCAL, 2275 bytes)
20/03/13 08:29:20 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 12616 ms on 192.168.222.178 (executor 2) (2/4)
20/03/13 08:29:20 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.222.178:36056 (size: 24.6 KB, free: 267.2 MB)
20/03/13 08:29:24 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 4735 ms on 192.168.222.178 (executor 1) (3/4)
20/03/13 08:29:24 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (join at /home/cloudera/pythondemo/retail/src/main/python/DailyRevenuePerProduct.py:14) finished in 19.026 s
20/03/13 08:29:24 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 4048 ms on 192.168.222.178 (executor 2) (4/4)
20/03/13 08:29:24 INFO scheduler.DAGScheduler: looking for newly runnable stages
20/03/13 08:29:24 INFO scheduler.DAGScheduler: running: Set()
20/03/13 08:29:24 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/03/13 08:29:24 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 1, ShuffleMapStage 2, ResultStage 3)
20/03/13 08:29:24 INFO scheduler.DAGScheduler: failed: Set()
20/03/13 08:29:24 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[12] at reduceByKey at /home/cloudera/pythondemo/retail/src/main/python/DailyRevenuePerProduct.py:17), which has no missing parents
20/03/13 08:29:24 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 9.5 KB, free 534.1 MB)
20/03/13 08:29:24 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.0 KB, free 534.0 MB)
20/03/13 08:29:24 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.222.178:58973 (size: 6.0 KB, free: 534.5 MB)
20/03/13 08:29:24 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004
20/03/13 08:29:24 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (PairwiseRDD[12] at reduceByKey at /home/cloudera/pythondemo/retail/src/main/python/DailyRevenuePerProduct.py:17) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/03/13 08:29:24 INFO cluster.YarnScheduler: Adding task set 1.0 with 4 tasks
20/03/13 08:29:24 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 4, 192.168.222.178, executor 1, partition 0, NODE_LOCAL, 1883 bytes)
20/03/13 08:29:24 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 5, 192.168.222.178, executor 2, partition 1, NODE_LOCAL, 1883 bytes)
20/03/13 08:29:24 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.222.178:46321 (size: 6.0 KB, free: 267.2 MB)
20/03/13 08:29:24 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.222.178:36056 (size: 6.0 KB, free: 267.2 MB)
20/03/13 08:29:25 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 192.168.222.178:34179
20/03/13 08:29:25 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 192.168.222.178:34183
20/03/13 08:29:25 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 173 bytes
20/03/13 08:29:26 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 1.0 (TID 6, 192.168.222.178, executor 1, partition 2, NODE_LOCAL, 1883 bytes)
20/03/13 08:29:26 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 4) in 1542 ms on 192.168.222.178 (executor 1) (1/4)
20/03/13 08:29:26 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 1.0 (TID 7, 192.168.222.178, executor 2, partition 3, NODE_LOCAL, 1883 bytes)
20/03/13 08:29:26 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 5) in 1672 ms on 192.168.222.178 (executor 2) (2/4)
20/03/13 08:29:27 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 1.0 (TID 6) in 1422 ms on 192.168.222.178 (executor 1) (3/4)
20/03/13 08:29:27 INFO scheduler.DAGScheduler: ShuffleMapStage 1 (reduceByKey at /home/cloudera/pythondemo/retail/src/main/python/DailyRevenuePerProduct.py:17) finished in 3.010 s
20/03/13 08:29:27 INFO scheduler.DAGScheduler: looking for newly runnable stages
20/03/13 08:29:27 INFO scheduler.DAGScheduler: running: Set()
20/03/13 08:29:27 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
20/03/13 08:29:27 INFO scheduler.DAGScheduler: failed: Set()
20/03/13 08:29:27 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (PairwiseRDD[20] at join at /home/cloudera/pythondemo/retail/src/main/python/DailyRevenuePerProduct.py:24), which has no missing parents
20/03/13 08:29:27 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 1.0 (TID 7) in 1342 ms on 192.168.222.178 (executor 2) (4/4)
20/03/13 08:29:27 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/03/13 08:29:27 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 11.2 KB, free 534.0 MB)
20/03/13 08:29:27 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.2 KB, free 534.0 MB)
20/03/13 08:29:27 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.222.178:58973 (size: 6.2 KB, free: 534.5 MB)
20/03/13 08:29:27 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1004
20/03/13 08:29:27 INFO scheduler.DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 2 (PairwiseRDD[20] at join at /home/cloudera/pythondemo/retail/src/main/python/DailyRevenuePerProduct.py:24) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
20/03/13 08:29:27 INFO cluster.YarnScheduler: Adding task set 2.0 with 6 tasks
20/03/13 08:29:27 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 8, 192.168.222.178, executor 2, partition 0, NODE_LOCAL, 1992 bytes)
20/03/13 08:29:27 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 9, 192.168.222.178, executor 1, partition 1, NODE_LOCAL, 1992 bytes)
20/03/13 08:29:28 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.222.178:46321 (size: 6.2 KB, free: 267.2 MB)
20/03/13 08:29:28 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.222.178:36056 (size: 6.2 KB, free: 267.2 MB)
20/03/13 08:29:28 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 192.168.222.178:34179
20/03/13 08:29:28 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 174 bytes
20/03/13 08:29:28 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 192.168.222.178:34183
20/03/13 08:29:28 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 2.0 (TID 10, 192.168.222.178, executor 1, partition 2, NODE_LOCAL, 1992 bytes)
20/03/13 08:29:28 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 9) in 469 ms on 192.168.222.178 (executor 1) (1/6)
20/03/13 08:29:28 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 2.0 (TID 11, 192.168.222.178, executor 2, partition 3, NODE_LOCAL, 1992 bytes)
20/03/13 08:29:28 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 8) in 530 ms on 192.168.222.178 (executor 2) (2/6)
20/03/13 08:29:28 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 2.0 (TID 12, 192.168.222.178, executor 1, partition 4, PROCESS_LOCAL, 90604 bytes)
20/03/13 08:29:28 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 2.0 (TID 10) in 379 ms on 192.168.222.178 (executor 1) (3/6)
20/03/13 08:29:28 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 2.0 (TID 13, 192.168.222.178, executor 2, partition 5, PROCESS_LOCAL, 94471 bytes)
20/03/13 08:29:28 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 2.0 (TID 11) in 429 ms on 192.168.222.178 (executor 2) (4/6)
20/03/13 08:29:29 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 2.0 (TID 12) in 346 ms on 192.168.222.178 (executor 1) (5/6)
20/03/13 08:29:29 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (join at /home/cloudera/pythondemo/retail/src/main/python/DailyRevenuePerProduct.py:24) finished in 1.183 s
20/03/13 08:29:29 INFO scheduler.DAGScheduler: looking for newly runnable stages
20/03/13 08:29:29 INFO scheduler.DAGScheduler: running: Set()
20/03/13 08:29:29 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 3)
20/03/13 08:29:29 INFO scheduler.DAGScheduler: failed: Set()
20/03/13 08:29:29 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[29] at saveAsTextFile at NativeMethodAccessorImpl.java:-2), which has no missing parents
20/03/13 08:29:29 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 2.0 (TID 13) in 241 ms on 192.168.222.178 (executor 2) (6/6)
20/03/13 08:29:29 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/03/13 08:29:29 INFO storage.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 85.6 KB, free 533.9 MB)
20/03/13 08:29:29 INFO storage.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.2 KB, free 533.9 MB)
20/03/13 08:29:29 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.222.178:58973 (size: 32.2 KB, free: 534.4 MB)
20/03/13 08:29:29 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1004
20/03/13 08:29:29 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[29] at saveAsTextFile at NativeMethodAccessorImpl.java:-2) (first 15 tasks are for partitions Vector(0))
20/03/13 08:29:29 INFO cluster.YarnScheduler: Adding task set 3.0 with 1 tasks
20/03/13 08:29:29 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 14, 192.168.222.178, executor 2, partition 0, NODE_LOCAL, 2298 bytes)
20/03/13 08:29:29 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.222.178:36056 (size: 32.2 KB, free: 267.2 MB)
20/03/13 08:29:29 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 192.168.222.178:34183
20/03/13 08:29:29 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 197 bytes
20/03/13 08:29:31 INFO scheduler.DAGScheduler: ResultStage 3 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) finished in 1.844 s
20/03/13 08:29:31 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 14) in 1845 ms on 192.168.222.178 (executor 2) (1/1)
20/03/13 08:29:31 INFO cluster.YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/03/13 08:29:31 INFO scheduler.DAGScheduler: Job 0 finished: saveAsTextFile at NativeMethodAccessorImpl.java:-2, took 26.245773 s
20/03/13 08:29:31 INFO spark.SparkContext: Invoking stop() from shutdown hook
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
20/03/13 08:29:31 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
20/03/13 08:29:31 INFO ui.SparkUI: Stopped Spark web UI at http://192.168.222.178:4043
20/03/13 08:29:31 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread
20/03/13 08:29:31 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
20/03/13 08:29:31 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down
20/03/13 08:29:31 INFO cluster.YarnClientSchedulerBackend: Stopped
20/03/13 08:29:32 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/03/13 08:29:32 INFO storage.MemoryStore: MemoryStore cleared
20/03/13 08:29:32 INFO storage.BlockManager: BlockManager stopped
20/03/13 08:29:32 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
20/03/13 08:29:32 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/03/13 08:29:32 INFO spark.SparkContext: Successfully stopped SparkContext
20/03/13 08:29:32 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
20/03/13 08:29:32 INFO util.ShutdownHookManager: Shutdown hook called
20/03/13 08:29:32 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-426a3a48-f98c-4ebf-bef7-23d6ae913673
20/03/13 08:29:32 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-426a3a48-f98c-4ebf-bef7-23d6ae913673/pyspark-1199836f-b559-4d70-bfae-e2fe37bc4020
[cloudera@quickstart retail]$ 
[cloudera@quickstart retail]$ hdfs dfs -ls /OutputFiles/retail_db/dailyRevenuePerProductName_text
Found 2 items
-rw-r--r--   1 cloudera supergroup          0 2020-03-13 08:29 /OutputFiles/retail_db/dailyRevenuePerProductName_text/_SUCCESS
-rw-r--r--   1 cloudera supergroup     503571 2020-03-13 08:29 /OutputFiles/retail_db/dailyRevenuePerProductName_text/part-00000
[cloudera@quickstart retail]$ hdfs dfs -cat /OutputFiles/retail_db/dailyRevenuePerProductName_text/part-00000 | head
2013-07-25,5599.72,Field & Stream Sportsman 16 Gun Fire Safe
2013-07-25,5099.49,Nike Men's Free 5.0+ Running Shoe
2013-07-25,4499.7,Diamondback Women's Serene Classic Comfort Bi
2013-07-25,3359.44,Perfect Fitness Perfect Rip Deck
2013-07-25,2999.85,Pelican Sunstream 100 Kayak
2013-07-25,2798.88,O'Brien Men's Neoprene Life Vest
2013-07-25,1949.85,Nike Men's CJ Elite 2 TD Football Cleat
2013-07-25,1650.0,Nike Men's Dri-FIT Victory Golf Polo
2013-07-25,1079.73,Under Armour Girls' Toddler Spine Surge Runni
2013-07-25,599.99,Bowflex SelectTech 1090 Dumbbells
