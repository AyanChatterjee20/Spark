[cloudera@quickstart spark]$ spark-submit --master yarn --conf spark.ui.port=4043 --num-executors 2 --executor-memory 512M src/main/python/nasaLogAnalysisRDD.py
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/zookeeper/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/flume-ng/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/parquet/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/avro/avro-tools-1.7.6-cdh5.13.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/03/13 07:43:30 INFO spark.SparkContext: Running Spark version 1.6.0
20/03/13 07:43:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/03/13 07:43:32 WARN util.Utils: Your hostname, quickstart.cloudera resolves to a loopback address: 127.0.0.1; using 192.168.222.178 instead (on interface eth1)
20/03/13 07:43:32 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address
20/03/13 07:43:32 INFO spark.SecurityManager: Changing view acls to: cloudera
20/03/13 07:43:32 INFO spark.SecurityManager: Changing modify acls to: cloudera
20/03/13 07:43:32 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(cloudera); users with modify permissions: Set(cloudera)
20/03/13 07:43:33 INFO util.Utils: Successfully started service 'sparkDriver' on port 34982.
20/03/13 07:43:34 INFO slf4j.Slf4jLogger: Slf4jLogger started
20/03/13 07:43:34 INFO Remoting: Starting remoting
20/03/13 07:43:34 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.222.178:53029]
20/03/13 07:43:34 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@192.168.222.178:53029]
20/03/13 07:43:34 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 53029.
20/03/13 07:43:34 INFO spark.SparkEnv: Registering MapOutputTracker
20/03/13 07:43:34 INFO spark.SparkEnv: Registering BlockManagerMaster
20/03/13 07:43:34 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-4666a67d-e993-4262-b8fe-77663a50d3ee
20/03/13 07:43:35 INFO storage.MemoryStore: MemoryStore started with capacity 534.5 MB
20/03/13 07:43:35 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/03/13 07:43:36 INFO server.Server: jetty-8.y.z-SNAPSHOT
20/03/13 07:43:36 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4043
20/03/13 07:43:36 INFO util.Utils: Successfully started service 'SparkUI' on port 4043.
20/03/13 07:43:36 INFO ui.SparkUI: Started SparkUI at http://192.168.222.178:4043
20/03/13 07:43:37 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
20/03/13 07:43:38 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers
20/03/13 07:43:38 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
20/03/13 07:43:38 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/03/13 07:43:38 INFO yarn.Client: Setting up container launch context for our AM
20/03/13 07:43:38 INFO yarn.Client: Setting up the launch environment for our AM container
20/03/13 07:43:38 INFO yarn.Client: Preparing resources for our AM container
20/03/13 07:43:40 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
20/03/13 07:43:40 INFO yarn.Client: Uploading resource file:/usr/lib/spark/lib/spark-assembly-1.6.0-cdh5.13.0-hadoop2.6.0-cdh5.13.0.jar -> hdfs://quickstart.cloudera:8020/user/cloudera/.sparkStaging/application_1581487397453_0110/spark-assembly-1.6.0-cdh5.13.0-hadoop2.6.0-cdh5.13.0.jar
20/03/13 07:43:44 INFO yarn.Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://quickstart.cloudera:8020/user/cloudera/.sparkStaging/application_1581487397453_0110/pyspark.zip
20/03/13 07:43:44 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1281)
	at java.lang.Thread.join(Thread.java:1355)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:967)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:705)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:894)
20/03/13 07:43:44 INFO yarn.Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.9-src.zip -> hdfs://quickstart.cloudera:8020/user/cloudera/.sparkStaging/application_1581487397453_0110/py4j-0.9-src.zip
20/03/13 07:43:44 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1281)
	at java.lang.Thread.join(Thread.java:1355)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:967)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:705)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:894)
20/03/13 07:43:44 INFO yarn.Client: Uploading resource file:/tmp/spark-b3e580f0-9cfa-441b-8b3d-93a95d0ec78d/__spark_conf__4071024846313781562.zip -> hdfs://quickstart.cloudera:8020/user/cloudera/.sparkStaging/application_1581487397453_0110/__spark_conf__4071024846313781562.zip
20/03/13 07:43:44 INFO spark.SecurityManager: Changing view acls to: cloudera
20/03/13 07:43:44 INFO spark.SecurityManager: Changing modify acls to: cloudera
20/03/13 07:43:44 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(cloudera); users with modify permissions: Set(cloudera)
20/03/13 07:43:44 INFO yarn.Client: Submitting application 110 to ResourceManager
20/03/13 07:43:45 INFO impl.YarnClientImpl: Submitted application application_1581487397453_0110
20/03/13 07:43:46 INFO yarn.Client: Application report for application_1581487397453_0110 (state: ACCEPTED)
20/03/13 07:43:46 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: root.cloudera
	 start time: 1584065625047
	 final status: UNDEFINED
	 tracking URL: http://quickstart.cloudera:8088/proxy/application_1581487397453_0110/
	 user: cloudera
20/03/13 07:43:47 INFO yarn.Client: Application report for application_1581487397453_0110 (state: ACCEPTED)
20/03/13 07:43:48 INFO yarn.Client: Application report for application_1581487397453_0110 (state: ACCEPTED)
20/03/13 07:43:49 INFO yarn.Client: Application report for application_1581487397453_0110 (state: ACCEPTED)
20/03/13 07:43:50 INFO yarn.Client: Application report for application_1581487397453_0110 (state: ACCEPTED)
20/03/13 07:43:51 INFO yarn.Client: Application report for application_1581487397453_0110 (state: ACCEPTED)
20/03/13 07:43:52 INFO yarn.Client: Application report for application_1581487397453_0110 (state: ACCEPTED)
20/03/13 07:43:53 INFO yarn.Client: Application report for application_1581487397453_0110 (state: ACCEPTED)
20/03/13 07:43:54 INFO yarn.Client: Application report for application_1581487397453_0110 (state: ACCEPTED)
20/03/13 07:43:55 INFO yarn.Client: Application report for application_1581487397453_0110 (state: ACCEPTED)
20/03/13 07:43:56 INFO yarn.Client: Application report for application_1581487397453_0110 (state: ACCEPTED)
20/03/13 07:43:57 INFO yarn.Client: Application report for application_1581487397453_0110 (state: ACCEPTED)
20/03/13 07:43:58 INFO yarn.Client: Application report for application_1581487397453_0110 (state: ACCEPTED)
20/03/13 07:43:58 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null)
20/03/13 07:43:58 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> quickstart.cloudera, PROXY_URI_BASES -> http://quickstart.cloudera:8088/proxy/application_1581487397453_0110), /proxy/application_1581487397453_0110
20/03/13 07:43:58 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
20/03/13 07:43:59 INFO yarn.Client: Application report for application_1581487397453_0110 (state: ACCEPTED)
20/03/13 07:44:00 INFO yarn.Client: Application report for application_1581487397453_0110 (state: ACCEPTED)
20/03/13 07:44:01 INFO yarn.Client: Application report for application_1581487397453_0110 (state: RUNNING)
20/03/13 07:44:01 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 192.168.222.178
	 ApplicationMaster RPC port: 0
	 queue: root.cloudera
	 start time: 1584065625047
	 final status: UNDEFINED
	 tracking URL: http://quickstart.cloudera:8088/proxy/application_1581487397453_0110/
	 user: cloudera
20/03/13 07:44:01 INFO cluster.YarnClientSchedulerBackend: Application application_1581487397453_0110 has started running.
20/03/13 07:44:01 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52789.
20/03/13 07:44:01 INFO netty.NettyBlockTransferService: Server created on 52789
20/03/13 07:44:01 INFO storage.BlockManagerMaster: Trying to register BlockManager
20/03/13 07:44:01 INFO storage.BlockManagerMasterEndpoint: Registering block manager 192.168.222.178:52789 with 534.5 MB RAM, BlockManagerId(driver, 192.168.222.178, 52789)
20/03/13 07:44:01 INFO storage.BlockManagerMaster: Registered BlockManager
20/03/13 07:44:07 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)
20/03/13 07:44:13 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 100.0 KB, free 534.4 MB)
20/03/13 07:44:14 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.6 KB, free 534.4 MB)
20/03/13 07:44:14 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.222.178:52789 (size: 24.6 KB, free: 534.5 MB)
20/03/13 07:44:14 INFO spark.SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2
20/03/13 07:44:16 INFO mapred.FileInputFormat: Total input paths to process : 2
Top 10 requested URLs along with count of number of times they have been requested :
20/03/13 07:44:19 INFO spark.SparkContext: Starting job: runJob at PythonRDD.scala:393
20/03/13 07:44:19 INFO scheduler.DAGScheduler: Registering RDD 4 (reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:50)
20/03/13 07:44:19 INFO scheduler.DAGScheduler: Got job 0 (runJob at PythonRDD.scala:393) with 1 output partitions
20/03/13 07:44:19 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (runJob at PythonRDD.scala:393)
20/03/13 07:44:19 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
20/03/13 07:44:19 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0)
20/03/13 07:44:19 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[4] at reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:50), which has no missing parents
20/03/13 07:44:20 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.4 KB, free 534.4 MB)
20/03/13 07:44:20 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KB, free 534.4 MB)
20/03/13 07:44:20 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.222.178:52789 (size: 6.1 KB, free: 534.5 MB)
20/03/13 07:44:20 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1004
20/03/13 07:44:20 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 0 (PairwiseRDD[4] at reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:50) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/03/13 07:44:20 INFO cluster.YarnScheduler: Adding task set 0.0 with 4 tasks
20/03/13 07:44:29 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (192.168.222.178:56595) with ID 2
20/03/13 07:44:29 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.222.178, executor 2, partition 0, RACK_LOCAL, 2156 bytes)
20/03/13 07:44:29 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (192.168.222.178:56594) with ID 1
20/03/13 07:44:29 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 192.168.222.178, executor 1, partition 1, RACK_LOCAL, 2156 bytes)
20/03/13 07:44:29 INFO storage.BlockManagerMasterEndpoint: Registering block manager 192.168.222.178:40970 with 267.3 MB RAM, BlockManagerId(2, 192.168.222.178, 40970)
20/03/13 07:44:29 INFO storage.BlockManagerMasterEndpoint: Registering block manager 192.168.222.178:48369 with 267.3 MB RAM, BlockManagerId(1, 192.168.222.178, 48369)
20/03/13 07:44:31 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.222.178:48369 (size: 6.1 KB, free: 267.3 MB)
20/03/13 07:44:31 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.222.178:40970 (size: 6.1 KB, free: 267.3 MB)
20/03/13 07:44:33 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.222.178:40970 (size: 24.6 KB, free: 267.2 MB)
20/03/13 07:44:33 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.222.178:48369 (size: 24.6 KB, free: 267.2 MB)
20/03/13 07:45:42 INFO storage.BlockManagerInfo: Added rdd_2_1 in memory on 192.168.222.178:48369 (size: 7.9 MB, free: 259.4 MB)
20/03/13 07:45:45 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 192.168.222.178, executor 1, partition 2, RACK_LOCAL, 2156 bytes)
20/03/13 07:45:45 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 75783 ms on 192.168.222.178 (executor 1) (1/4)
20/03/13 07:48:16 INFO storage.BlockManagerInfo: Added rdd_2_0 in memory on 192.168.222.178:40970 (size: 31.4 MB, free: 235.8 MB)
20/03/13 07:48:27 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 192.168.222.178, executor 2, partition 3, RACK_LOCAL, 2156 bytes)
20/03/13 07:48:27 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 238429 ms on 192.168.222.178 (executor 2) (2/4)
20/03/13 07:49:11 INFO storage.BlockManagerInfo: Added rdd_2_2 in memory on 192.168.222.178:48369 (size: 32.4 MB, free: 226.9 MB)
20/03/13 07:49:18 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 213539 ms on 192.168.222.178 (executor 1) (3/4)
20/03/13 07:49:46 INFO storage.BlockManagerInfo: Added rdd_2_3 in memory on 192.168.222.178:40970 (size: 16.9 MB, free: 218.9 MB)
20/03/13 07:49:50 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 82216 ms on 192.168.222.178 (executor 2) (4/4)
20/03/13 07:49:50 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:50) finished in 329.681 s
20/03/13 07:49:50 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/03/13 07:49:50 INFO scheduler.DAGScheduler: looking for newly runnable stages
20/03/13 07:49:50 INFO scheduler.DAGScheduler: running: Set()
20/03/13 07:49:50 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1)
20/03/13 07:49:50 INFO scheduler.DAGScheduler: failed: Set()
20/03/13 07:49:50 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (PythonRDD[43] at RDD at PythonRDD.scala:43), which has no missing parents
20/03/13 07:49:50 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.7 KB, free 534.4 MB)
20/03/13 07:49:50 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 534.4 MB)
20/03/13 07:49:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.222.178:52789 (size: 4.5 KB, free: 534.5 MB)
20/03/13 07:49:50 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004
20/03/13 07:49:50 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (PythonRDD[43] at RDD at PythonRDD.scala:43) (first 15 tasks are for partitions Vector(0))
20/03/13 07:49:50 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks
20/03/13 07:49:50 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 4, 192.168.222.178, executor 2, partition 0, NODE_LOCAL, 2217 bytes)
20/03/13 07:49:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.222.178:40970 (size: 4.5 KB, free: 218.9 MB)
20/03/13 07:49:50 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 192.168.222.178:56595
20/03/13 07:49:50 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 180 bytes
20/03/13 07:49:51 INFO scheduler.DAGScheduler: ResultStage 1 (runJob at PythonRDD.scala:393) finished in 1.599 s
20/03/13 07:49:51 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 4) in 1602 ms on 192.168.222.178 (executor 2) (1/1)
20/03/13 07:49:51 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/03/13 07:49:51 INFO scheduler.DAGScheduler: Job 0 finished: runJob at PythonRDD.scala:393, took 332.554252 s
(u'/images/NASA-logosmall.gif', 208798)
(u'/images/KSC-logosmall.gif', 164976)
(u'/images/MOSAIC-logosmall.gif', 127916)
(u'/images/USA-logosmall.gif', 127082)
(u'/images/WORLD-logosmall.gif', 125933)
(u'/images/ksclogo-medium.gif', 121580)
(u'/ksc.html', 83918)
(u'/images/launch-logo.gif', 76009)
(u'/history/apollo/images/apollo-logo1.gif', 68898)
(u'/shuttle/countdown/', 64740)
 
Top 5 hosts / IP making the request along with count :
20/03/13 07:49:52 INFO spark.SparkContext: Starting job: runJob at PythonRDD.scala:393
20/03/13 07:49:52 INFO scheduler.DAGScheduler: Registering RDD 10 (reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:56)
20/03/13 07:49:52 INFO scheduler.DAGScheduler: Got job 1 (runJob at PythonRDD.scala:393) with 1 output partitions
20/03/13 07:49:52 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (runJob at PythonRDD.scala:393)
20/03/13 07:49:52 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
20/03/13 07:49:52 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 2)
20/03/13 07:49:52 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (PairwiseRDD[10] at reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:56), which has no missing parents
20/03/13 07:49:52 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.4 KB, free 534.4 MB)
20/03/13 07:49:52 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.1 KB, free 534.4 MB)
20/03/13 07:49:52 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.222.178:52789 (size: 6.1 KB, free: 534.5 MB)
20/03/13 07:49:52 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004
20/03/13 07:49:52 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 2 (PairwiseRDD[10] at reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:56) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/03/13 07:49:52 INFO cluster.YarnScheduler: Adding task set 2.0 with 4 tasks
20/03/13 07:49:52 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, 192.168.222.178, executor 1, partition 1, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:49:52 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 6, 192.168.222.178, executor 2, partition 0, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:49:52 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.222.178:40970 (size: 6.1 KB, free: 218.9 MB)
20/03/13 07:49:52 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.222.178:48369 (size: 6.1 KB, free: 226.9 MB)
20/03/13 07:49:54 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7, 192.168.222.178, executor 1, partition 2, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:49:54 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 2637 ms on 192.168.222.178 (executor 1) (1/4)
20/03/13 07:50:02 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 2.0 (TID 8, 192.168.222.178, executor 2, partition 3, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:50:02 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 6) in 10349 ms on 192.168.222.178 (executor 2) (2/4)
20/03/13 07:50:05 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 2.0 (TID 7) in 11032 ms on 192.168.222.178 (executor 1) (3/4)
20/03/13 07:50:07 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:56) finished in 15.450 s
20/03/13 07:50:07 INFO scheduler.DAGScheduler: looking for newly runnable stages
20/03/13 07:50:07 INFO scheduler.DAGScheduler: running: Set()
20/03/13 07:50:07 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 3)
20/03/13 07:50:07 INFO scheduler.DAGScheduler: failed: Set()
20/03/13 07:50:07 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (PythonRDD[44] at RDD at PythonRDD.scala:43), which has no missing parents
20/03/13 07:50:07 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 2.0 (TID 8) in 5124 ms on 192.168.222.178 (executor 2) (4/4)
20/03/13 07:50:07 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/03/13 07:50:07 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.7 KB, free 534.4 MB)
20/03/13 07:50:07 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 534.4 MB)
20/03/13 07:50:07 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.222.178:52789 (size: 4.5 KB, free: 534.5 MB)
20/03/13 07:50:07 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1004
20/03/13 07:50:07 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (PythonRDD[44] at RDD at PythonRDD.scala:43) (first 15 tasks are for partitions Vector(0))
20/03/13 07:50:07 INFO cluster.YarnScheduler: Adding task set 3.0 with 1 tasks
20/03/13 07:50:07 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 9, 192.168.222.178, executor 1, partition 0, NODE_LOCAL, 2217 bytes)
20/03/13 07:50:07 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.222.178:48369 (size: 4.5 KB, free: 226.9 MB)
20/03/13 07:50:07 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 192.168.222.178:56594
20/03/13 07:50:07 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 175 bytes
20/03/13 07:50:10 INFO scheduler.DAGScheduler: ResultStage 3 (runJob at PythonRDD.scala:393) finished in 3.432 s
20/03/13 07:50:10 INFO scheduler.DAGScheduler: Job 1 finished: runJob at PythonRDD.scala:393, took 18.956847 s
20/03/13 07:50:10 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 9) in 3432 ms on 192.168.222.178 (executor 1) (1/1)
20/03/13 07:50:10 INFO cluster.YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
(u'piweba3y.prodigy.com', 21988)
(u'piweba4y.prodigy.com', 16437)
(u'piweba1y.prodigy.com', 12825)
(u'edams.ksc.nasa.gov', 11964)
(u'163.206.89.4', 9697)
 
Top 5 Hour in a day frame for high traffic :
20/03/13 07:50:11 INFO spark.SparkContext: Starting job: runJob at PythonRDD.scala:393
20/03/13 07:50:11 INFO scheduler.DAGScheduler: Registering RDD 16 (reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:63)
20/03/13 07:50:11 INFO scheduler.DAGScheduler: Got job 2 (runJob at PythonRDD.scala:393) with 1 output partitions
20/03/13 07:50:11 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (runJob at PythonRDD.scala:393)
20/03/13 07:50:11 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
20/03/13 07:50:11 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 4)
20/03/13 07:50:11 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 4 (PairwiseRDD[16] at reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:63), which has no missing parents
20/03/13 07:50:11 INFO storage.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.4 KB, free 534.3 MB)
20/03/13 07:50:11 INFO storage.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.1 KB, free 534.3 MB)
20/03/13 07:50:11 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.222.178:52789 (size: 6.1 KB, free: 534.5 MB)
20/03/13 07:50:11 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1004
20/03/13 07:50:11 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 4 (PairwiseRDD[16] at reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:63) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/03/13 07:50:11 INFO cluster.YarnScheduler: Adding task set 4.0 with 4 tasks
20/03/13 07:50:11 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, 192.168.222.178, executor 2, partition 0, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:50:11 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 11, 192.168.222.178, executor 1, partition 1, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:50:11 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.222.178:40970 (size: 6.1 KB, free: 218.9 MB)
20/03/13 07:50:11 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.222.178:48369 (size: 6.1 KB, free: 226.9 MB)
20/03/13 07:50:18 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 4.0 (TID 12, 192.168.222.178, executor 1, partition 2, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:50:18 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 4.0 (TID 11) in 7498 ms on 192.168.222.178 (executor 1) (1/4)
20/03/13 07:50:28 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 4.0 (TID 13, 192.168.222.178, executor 2, partition 3, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:50:28 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 16974 ms on 192.168.222.178 (executor 2) (2/4)
20/03/13 07:50:30 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 4.0 (TID 12) in 11694 ms on 192.168.222.178 (executor 1) (3/4)
20/03/13 07:50:31 INFO scheduler.DAGScheduler: ShuffleMapStage 4 (reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:63) finished in 20.415 s
20/03/13 07:50:31 INFO scheduler.DAGScheduler: looking for newly runnable stages
20/03/13 07:50:31 INFO scheduler.DAGScheduler: running: Set()
20/03/13 07:50:31 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 5)
20/03/13 07:50:31 INFO scheduler.DAGScheduler: failed: Set()
20/03/13 07:50:31 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (PythonRDD[45] at RDD at PythonRDD.scala:43), which has no missing parents
20/03/13 07:50:31 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 4.0 (TID 13) in 3452 ms on 192.168.222.178 (executor 2) (4/4)
20/03/13 07:50:31 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/03/13 07:50:31 INFO storage.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.7 KB, free 534.3 MB)
20/03/13 07:50:31 INFO storage.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.5 KB, free 534.3 MB)
20/03/13 07:50:31 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.222.178:52789 (size: 4.5 KB, free: 534.5 MB)
20/03/13 07:50:31 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1004
20/03/13 07:50:31 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (PythonRDD[45] at RDD at PythonRDD.scala:43) (first 15 tasks are for partitions Vector(0))
20/03/13 07:50:31 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks
20/03/13 07:50:31 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 14, 192.168.222.178, executor 2, partition 0, NODE_LOCAL, 2217 bytes)
20/03/13 07:50:31 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.222.178:40970 (size: 4.5 KB, free: 218.9 MB)
20/03/13 07:50:31 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 192.168.222.178:56595
20/03/13 07:50:31 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 163 bytes
20/03/13 07:50:32 INFO scheduler.DAGScheduler: ResultStage 5 (runJob at PythonRDD.scala:393) finished in 0.462 s
20/03/13 07:50:32 INFO scheduler.DAGScheduler: Job 2 finished: runJob at PythonRDD.scala:393, took 21.016996 s
20/03/13 07:50:32 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 14) in 463 ms on 192.168.222.178 (executor 2) (1/1)
20/03/13 07:50:32 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool 
(u'15', 230660)
(u'12', 227228)
(u'13', 225349)
(u'14', 223872)
(u'16', 217563)
 
Top 5 day in a month frame for high traffic :
20/03/13 07:50:32 INFO spark.SparkContext: Starting job: runJob at PythonRDD.scala:393
20/03/13 07:50:32 INFO scheduler.DAGScheduler: Registering RDD 22 (reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:66)
20/03/13 07:50:32 INFO scheduler.DAGScheduler: Got job 3 (runJob at PythonRDD.scala:393) with 1 output partitions
20/03/13 07:50:32 INFO scheduler.DAGScheduler: Final stage: ResultStage 7 (runJob at PythonRDD.scala:393)
20/03/13 07:50:32 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
20/03/13 07:50:32 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 6)
20/03/13 07:50:32 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 6 (PairwiseRDD[22] at reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:66), which has no missing parents
20/03/13 07:50:32 INFO storage.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 10.4 KB, free 534.3 MB)
20/03/13 07:50:32 INFO storage.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.1 KB, free 534.3 MB)
20/03/13 07:50:32 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.222.178:52789 (size: 6.1 KB, free: 534.5 MB)
20/03/13 07:50:32 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1004
20/03/13 07:50:32 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (PairwiseRDD[22] at reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:66) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/03/13 07:50:32 INFO cluster.YarnScheduler: Adding task set 6.0 with 4 tasks
20/03/13 07:50:32 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 15, 192.168.222.178, executor 2, partition 0, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:50:32 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 16, 192.168.222.178, executor 1, partition 1, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:50:32 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.222.178:40970 (size: 6.1 KB, free: 218.9 MB)
20/03/13 07:50:32 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.222.178:48369 (size: 6.1 KB, free: 226.9 MB)
20/03/13 07:50:36 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 6.0 (TID 17, 192.168.222.178, executor 1, partition 2, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:50:36 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 6.0 (TID 16) in 4370 ms on 192.168.222.178 (executor 1) (1/4)
20/03/13 07:50:49 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 6.0 (TID 18, 192.168.222.178, executor 2, partition 3, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:50:49 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 15) in 17017 ms on 192.168.222.178 (executor 2) (2/4)
20/03/13 07:50:53 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 6.0 (TID 17) in 16417 ms on 192.168.222.178 (executor 1) (3/4)
20/03/13 07:50:55 INFO scheduler.DAGScheduler: ShuffleMapStage 6 (reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:66) finished in 23.406 s
20/03/13 07:50:55 INFO scheduler.DAGScheduler: looking for newly runnable stages
20/03/13 07:50:55 INFO scheduler.DAGScheduler: running: Set()
20/03/13 07:50:55 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 7)
20/03/13 07:50:55 INFO scheduler.DAGScheduler: failed: Set()
20/03/13 07:50:55 INFO scheduler.DAGScheduler: Submitting ResultStage 7 (PythonRDD[46] at RDD at PythonRDD.scala:43), which has no missing parents
20/03/13 07:50:55 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 6.0 (TID 18) in 6409 ms on 192.168.222.178 (executor 2) (4/4)
20/03/13 07:50:55 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool 
20/03/13 07:50:55 INFO storage.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.7 KB, free 534.3 MB)
20/03/13 07:50:55 INFO storage.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.6 KB, free 534.3 MB)
20/03/13 07:50:55 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.222.178:52789 (size: 4.6 KB, free: 534.5 MB)
20/03/13 07:50:55 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1004
20/03/13 07:50:55 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (PythonRDD[46] at RDD at PythonRDD.scala:43) (first 15 tasks are for partitions Vector(0))
20/03/13 07:50:55 INFO cluster.YarnScheduler: Adding task set 7.0 with 1 tasks
20/03/13 07:50:55 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 19, 192.168.222.178, executor 1, partition 0, NODE_LOCAL, 2217 bytes)
20/03/13 07:50:55 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.222.178:48369 (size: 4.6 KB, free: 226.9 MB)
20/03/13 07:50:55 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 192.168.222.178:56594
20/03/13 07:50:55 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 179 bytes
20/03/13 07:50:56 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 19) in 407 ms on 192.168.222.178 (executor 1) (1/1)
20/03/13 07:50:56 INFO scheduler.DAGScheduler: ResultStage 7 (runJob at PythonRDD.scala:393) finished in 0.409 s
20/03/13 07:50:56 INFO scheduler.DAGScheduler: Job 3 finished: runJob at PythonRDD.scala:393, took 23.982599 s
20/03/13 07:50:56 INFO cluster.YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool 
(13, 170683)
(7, 144595)
(14, 143976)
(11, 141652)
(10, 134107)
 
Least 5 Hour in a day frame for low traffic :
20/03/13 07:50:56 INFO spark.SparkContext: Starting job: runJob at PythonRDD.scala:393
20/03/13 07:50:56 INFO scheduler.DAGScheduler: Registering RDD 28 (reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:73)
20/03/13 07:50:56 INFO scheduler.DAGScheduler: Got job 4 (runJob at PythonRDD.scala:393) with 1 output partitions
20/03/13 07:50:56 INFO scheduler.DAGScheduler: Final stage: ResultStage 9 (runJob at PythonRDD.scala:393)
20/03/13 07:50:56 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
20/03/13 07:50:56 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 8)
20/03/13 07:50:56 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 8 (PairwiseRDD[28] at reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:73), which has no missing parents
20/03/13 07:50:56 INFO storage.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 10.4 KB, free 534.3 MB)
20/03/13 07:50:56 INFO storage.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.1 KB, free 534.3 MB)
20/03/13 07:50:56 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.222.178:52789 (size: 6.1 KB, free: 534.5 MB)
20/03/13 07:50:56 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1004
20/03/13 07:50:56 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (PairwiseRDD[28] at reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:73) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/03/13 07:50:56 INFO cluster.YarnScheduler: Adding task set 8.0 with 4 tasks
20/03/13 07:50:56 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 20, 192.168.222.178, executor 2, partition 0, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:50:56 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 8.0 (TID 21, 192.168.222.178, executor 1, partition 1, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:50:56 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.222.178:40970 (size: 6.1 KB, free: 218.9 MB)
20/03/13 07:50:56 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.222.178:48369 (size: 6.1 KB, free: 226.9 MB)
20/03/13 07:51:00 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 8.0 (TID 22, 192.168.222.178, executor 1, partition 2, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:51:00 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 8.0 (TID 21) in 3739 ms on 192.168.222.178 (executor 1) (1/4)
20/03/13 07:51:09 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 8.0 (TID 23, 192.168.222.178, executor 2, partition 3, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:51:09 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 20) in 13232 ms on 192.168.222.178 (executor 2) (2/4)
20/03/13 07:51:11 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 8.0 (TID 22) in 11577 ms on 192.168.222.178 (executor 1) (3/4)
20/03/13 07:51:13 INFO scheduler.DAGScheduler: ShuffleMapStage 8 (reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:73) finished in 16.605 s
20/03/13 07:51:13 INFO scheduler.DAGScheduler: looking for newly runnable stages
20/03/13 07:51:13 INFO scheduler.DAGScheduler: running: Set()
20/03/13 07:51:13 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 9)
20/03/13 07:51:13 INFO scheduler.DAGScheduler: failed: Set()
20/03/13 07:51:13 INFO scheduler.DAGScheduler: Submitting ResultStage 9 (PythonRDD[47] at RDD at PythonRDD.scala:43), which has no missing parents
20/03/13 07:51:13 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 8.0 (TID 23) in 3378 ms on 192.168.222.178 (executor 2) (4/4)
20/03/13 07:51:13 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool 
20/03/13 07:51:13 INFO storage.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.7 KB, free 534.3 MB)
20/03/13 07:51:13 INFO storage.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.5 KB, free 534.3 MB)
20/03/13 07:51:13 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.222.178:52789 (size: 4.5 KB, free: 534.5 MB)
20/03/13 07:51:13 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1004
20/03/13 07:51:13 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (PythonRDD[47] at RDD at PythonRDD.scala:43) (first 15 tasks are for partitions Vector(0))
20/03/13 07:51:13 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks
20/03/13 07:51:13 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 24, 192.168.222.178, executor 2, partition 0, NODE_LOCAL, 2217 bytes)
20/03/13 07:51:13 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.222.178:40970 (size: 4.5 KB, free: 218.8 MB)
20/03/13 07:51:13 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.222.178:56595
20/03/13 07:51:13 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 163 bytes
20/03/13 07:51:13 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 24) in 351 ms on 192.168.222.178 (executor 2) (1/1)
20/03/13 07:51:13 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool 
20/03/13 07:51:13 INFO scheduler.DAGScheduler: ResultStage 9 (runJob at PythonRDD.scala:393) finished in 0.349 s
20/03/13 07:51:13 INFO scheduler.DAGScheduler: Job 4 finished: runJob at PythonRDD.scala:393, took 17.095714 s
(u'04', 58989)
(u'05', 59505)
(u'06', 66540)
(u'03', 67393)
(u'02', 77805)
 
Least 5 day in a month frame for low traffic :
20/03/13 07:51:13 INFO spark.SparkContext: Starting job: runJob at PythonRDD.scala:393
20/03/13 07:51:13 INFO scheduler.DAGScheduler: Registering RDD 34 (reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:76)
20/03/13 07:51:13 INFO scheduler.DAGScheduler: Got job 5 (runJob at PythonRDD.scala:393) with 1 output partitions
20/03/13 07:51:13 INFO scheduler.DAGScheduler: Final stage: ResultStage 11 (runJob at PythonRDD.scala:393)
20/03/13 07:51:13 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
20/03/13 07:51:13 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 10)
20/03/13 07:51:13 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 10 (PairwiseRDD[34] at reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:76), which has no missing parents
20/03/13 07:51:13 INFO storage.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 10.4 KB, free 534.3 MB)
20/03/13 07:51:13 INFO storage.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.1 KB, free 534.3 MB)
20/03/13 07:51:13 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.222.178:52789 (size: 6.1 KB, free: 534.5 MB)
20/03/13 07:51:13 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1004
20/03/13 07:51:13 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 10 (PairwiseRDD[34] at reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:76) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/03/13 07:51:13 INFO cluster.YarnScheduler: Adding task set 10.0 with 4 tasks
20/03/13 07:51:13 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 10.0 (TID 25, 192.168.222.178, executor 1, partition 1, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:51:13 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 26, 192.168.222.178, executor 2, partition 0, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:51:13 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.222.178:48369 (size: 6.1 KB, free: 226.9 MB)
20/03/13 07:51:13 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.222.178:40970 (size: 6.1 KB, free: 218.8 MB)
20/03/13 07:51:17 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 10.0 (TID 27, 192.168.222.178, executor 1, partition 2, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:51:17 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 10.0 (TID 25) in 4188 ms on 192.168.222.178 (executor 1) (1/4)
20/03/13 07:51:29 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 10.0 (TID 28, 192.168.222.178, executor 2, partition 3, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:51:29 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 26) in 16296 ms on 192.168.222.178 (executor 2) (2/4)
20/03/13 07:51:33 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 10.0 (TID 27) in 15561 ms on 192.168.222.178 (executor 1) (3/4)
20/03/13 07:51:35 INFO scheduler.DAGScheduler: ShuffleMapStage 10 (reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:76) finished in 22.164 s
20/03/13 07:51:35 INFO scheduler.DAGScheduler: looking for newly runnable stages
20/03/13 07:51:35 INFO scheduler.DAGScheduler: running: Set()
20/03/13 07:51:35 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 11)
20/03/13 07:51:35 INFO scheduler.DAGScheduler: failed: Set()
20/03/13 07:51:35 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 10.0 (TID 28) in 5878 ms on 192.168.222.178 (executor 2) (4/4)
20/03/13 07:51:35 INFO cluster.YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool 
20/03/13 07:51:35 INFO scheduler.DAGScheduler: Submitting ResultStage 11 (PythonRDD[48] at RDD at PythonRDD.scala:43), which has no missing parents
20/03/13 07:51:35 INFO storage.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.7 KB, free 534.2 MB)
20/03/13 07:51:35 INFO storage.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.5 KB, free 534.2 MB)
20/03/13 07:51:35 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.222.178:52789 (size: 4.5 KB, free: 534.4 MB)
20/03/13 07:51:35 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1004
20/03/13 07:51:35 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (PythonRDD[48] at RDD at PythonRDD.scala:43) (first 15 tasks are for partitions Vector(0))
20/03/13 07:51:35 INFO cluster.YarnScheduler: Adding task set 11.0 with 1 tasks
20/03/13 07:51:35 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 29, 192.168.222.178, executor 2, partition 0, NODE_LOCAL, 2217 bytes)
20/03/13 07:51:35 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.222.178:40970 (size: 4.5 KB, free: 218.8 MB)
20/03/13 07:51:35 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.222.178:56595
20/03/13 07:51:35 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 179 bytes
20/03/13 07:51:36 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 29) in 385 ms on 192.168.222.178 (executor 2) (1/1)
20/03/13 07:51:36 INFO scheduler.DAGScheduler: ResultStage 11 (runJob at PythonRDD.scala:393) finished in 0.383 s
20/03/13 07:51:36 INFO scheduler.DAGScheduler: Job 5 finished: runJob at PythonRDD.scala:393, took 22.687729 s
20/03/13 07:51:36 INFO cluster.YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool 
(2, 60265)
(29, 67988)
(30, 80641)
(28, 82617)
(31, 90124)
 
Unique HTTP codes returned by the server along with count :
20/03/13 07:51:36 INFO spark.SparkContext: Starting job: runJob at PythonRDD.scala:393
20/03/13 07:51:36 INFO scheduler.DAGScheduler: Registering RDD 40 (reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:82)
20/03/13 07:51:36 INFO scheduler.DAGScheduler: Got job 6 (runJob at PythonRDD.scala:393) with 1 output partitions
20/03/13 07:51:36 INFO scheduler.DAGScheduler: Final stage: ResultStage 13 (runJob at PythonRDD.scala:393)
20/03/13 07:51:36 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
20/03/13 07:51:36 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 12)
20/03/13 07:51:36 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 12 (PairwiseRDD[40] at reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:82), which has no missing parents
20/03/13 07:51:36 INFO storage.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 10.4 KB, free 534.2 MB)
20/03/13 07:51:36 INFO storage.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 6.1 KB, free 534.2 MB)
20/03/13 07:51:36 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.222.178:52789 (size: 6.1 KB, free: 534.4 MB)
20/03/13 07:51:36 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1004
20/03/13 07:51:36 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 12 (PairwiseRDD[40] at reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:82) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/03/13 07:51:36 INFO cluster.YarnScheduler: Adding task set 12.0 with 4 tasks
20/03/13 07:51:36 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 12.0 (TID 30, 192.168.222.178, executor 2, partition 0, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:51:36 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 12.0 (TID 31, 192.168.222.178, executor 1, partition 1, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:51:36 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.222.178:40970 (size: 6.1 KB, free: 218.8 MB)
20/03/13 07:51:36 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.222.178:48369 (size: 6.1 KB, free: 226.9 MB)
20/03/13 07:51:39 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 12.0 (TID 32, 192.168.222.178, executor 1, partition 2, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:51:39 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 12.0 (TID 31) in 3049 ms on 192.168.222.178 (executor 1) (1/4)
20/03/13 07:51:46 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 12.0 (TID 33, 192.168.222.178, executor 2, partition 3, PROCESS_LOCAL, 2156 bytes)
20/03/13 07:51:46 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 12.0 (TID 30) in 10420 ms on 192.168.222.178 (executor 2) (2/4)
20/03/13 07:51:49 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 12.0 (TID 32) in 10375 ms on 192.168.222.178 (executor 1) (3/4)
20/03/13 07:51:51 INFO scheduler.DAGScheduler: ShuffleMapStage 12 (reduceByKey at /home/cloudera/pythondemo/spark/src/main/python/nasaLogAnalysisRDD.py:82) finished in 15.136 s
20/03/13 07:51:51 INFO scheduler.DAGScheduler: looking for newly runnable stages
20/03/13 07:51:51 INFO scheduler.DAGScheduler: running: Set()
20/03/13 07:51:51 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 13)
20/03/13 07:51:51 INFO scheduler.DAGScheduler: failed: Set()
20/03/13 07:51:51 INFO scheduler.DAGScheduler: Submitting ResultStage 13 (PythonRDD[49] at RDD at PythonRDD.scala:43), which has no missing parents
20/03/13 07:51:51 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 12.0 (TID 33) in 4723 ms on 192.168.222.178 (executor 2) (4/4)
20/03/13 07:51:51 INFO cluster.YarnScheduler: Removed TaskSet 12.0, whose tasks have all completed, from pool 
20/03/13 07:51:51 INFO storage.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 5.4 KB, free 534.2 MB)
20/03/13 07:51:51 INFO storage.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.5 KB, free 534.2 MB)
20/03/13 07:51:51 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.222.178:52789 (size: 3.5 KB, free: 534.4 MB)
20/03/13 07:51:51 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1004
20/03/13 07:51:51 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (PythonRDD[49] at RDD at PythonRDD.scala:43) (first 15 tasks are for partitions Vector(0))
20/03/13 07:51:51 INFO cluster.YarnScheduler: Adding task set 13.0 with 1 tasks
20/03/13 07:51:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 34, 192.168.222.178, executor 2, partition 0, NODE_LOCAL, 1894 bytes)
20/03/13 07:51:51 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.222.178:40970 (size: 3.5 KB, free: 218.8 MB)
20/03/13 07:51:51 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 192.168.222.178:56595
20/03/13 07:51:51 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 177 bytes
20/03/13 07:51:51 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 34) in 178 ms on 192.168.222.178 (executor 2) (1/1)
20/03/13 07:51:51 INFO cluster.YarnScheduler: Removed TaskSet 13.0, whose tasks have all completed, from pool 
20/03/13 07:51:51 INFO scheduler.DAGScheduler: ResultStage 13 (runJob at PythonRDD.scala:393) finished in 0.175 s
20/03/13 07:51:51 INFO scheduler.DAGScheduler: Job 6 finished: runJob at PythonRDD.scala:393, took 15.498434 s
(u'35540', 4159)
(u'35236', 3)
(u'65093', 3)
(u'49910', 1)
(u'73465', 2)
(u'55339', 1)
(u'68919', 4)
(u'3571', 3)
(u'4022', 64)
(u'35232', 2)
20/03/13 07:51:52 INFO spark.SparkContext: Invoking stop() from shutdown hook
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
20/03/13 07:51:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
20/03/13 07:51:52 INFO ui.SparkUI: Stopped Spark web UI at http://192.168.222.178:4043
20/03/13 07:51:52 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread
20/03/13 07:51:52 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
20/03/13 07:51:52 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down
20/03/13 07:51:52 INFO cluster.YarnClientSchedulerBackend: Stopped
20/03/13 07:51:52 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/03/13 07:51:52 INFO storage.MemoryStore: MemoryStore cleared
20/03/13 07:51:52 INFO storage.BlockManager: BlockManager stopped
20/03/13 07:51:52 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
20/03/13 07:51:52 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/03/13 07:51:53 INFO spark.SparkContext: Successfully stopped SparkContext
20/03/13 07:51:53 INFO util.ShutdownHookManager: Shutdown hook called
20/03/13 07:51:53 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-b3e580f0-9cfa-441b-8b3d-93a95d0ec78d/pyspark-9be7b2ec-69af-447a-a16c-d00cfee4e410
20/03/13 07:51:53 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
20/03/13 07:51:53 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-b3e580f0-9cfa-441b-8b3d-93a95d0ec78d
