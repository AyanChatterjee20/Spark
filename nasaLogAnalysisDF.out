[cloudera@quickstart spark]$ spark-submit --master yarn --conf spark.ui.port=4043 --num-executors 2 --executor-memory 512M src/main/python/nasaLogAnalysisDF.py
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/zookeeper/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/flume-ng/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/parquet/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/avro/avro-tools-1.7.6-cdh5.13.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/03/10 09:05:12 INFO spark.SparkContext: Running Spark version 1.6.0
20/03/10 09:05:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/03/10 09:05:14 WARN util.Utils: Your hostname, quickstart.cloudera resolves to a loopback address: 127.0.0.1; using 192.168.222.174 instead (on interface eth1)
20/03/10 09:05:14 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address
20/03/10 09:05:14 INFO spark.SecurityManager: Changing view acls to: cloudera
20/03/10 09:05:14 INFO spark.SecurityManager: Changing modify acls to: cloudera
20/03/10 09:05:14 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(cloudera); users with modify permissions: Set(cloudera)
20/03/10 09:05:15 INFO util.Utils: Successfully started service 'sparkDriver' on port 33118.
20/03/10 09:05:15 INFO slf4j.Slf4jLogger: Slf4jLogger started
20/03/10 09:05:15 INFO Remoting: Starting remoting
20/03/10 09:05:16 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.222.174:47550]
20/03/10 09:05:16 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@192.168.222.174:47550]
20/03/10 09:05:16 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 47550.
20/03/10 09:05:16 INFO spark.SparkEnv: Registering MapOutputTracker
20/03/10 09:05:16 INFO spark.SparkEnv: Registering BlockManagerMaster
20/03/10 09:05:16 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-ca676acf-db3f-45d0-8f21-48b31513a477
20/03/10 09:05:16 INFO storage.MemoryStore: MemoryStore started with capacity 534.5 MB
20/03/10 09:05:17 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/03/10 09:05:17 INFO server.Server: jetty-8.y.z-SNAPSHOT
20/03/10 09:05:17 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4043
20/03/10 09:05:17 INFO util.Utils: Successfully started service 'SparkUI' on port 4043.
20/03/10 09:05:17 INFO ui.SparkUI: Started SparkUI at http://192.168.222.174:4043
20/03/10 09:05:18 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
20/03/10 09:05:19 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers
20/03/10 09:05:19 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
20/03/10 09:05:19 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/03/10 09:05:19 INFO yarn.Client: Setting up container launch context for our AM
20/03/10 09:05:19 INFO yarn.Client: Setting up the launch environment for our AM container
20/03/10 09:05:19 INFO yarn.Client: Preparing resources for our AM container
20/03/10 09:05:21 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
20/03/10 09:05:21 INFO yarn.Client: Uploading resource file:/usr/lib/spark/lib/spark-assembly-1.6.0-cdh5.13.0-hadoop2.6.0-cdh5.13.0.jar -> hdfs://quickstart.cloudera:8020/user/cloudera/.sparkStaging/application_1581487397453_0101/spark-assembly-1.6.0-cdh5.13.0-hadoop2.6.0-cdh5.13.0.jar
20/03/10 09:05:24 INFO yarn.Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://quickstart.cloudera:8020/user/cloudera/.sparkStaging/application_1581487397453_0101/pyspark.zip
20/03/10 09:05:25 INFO yarn.Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.9-src.zip -> hdfs://quickstart.cloudera:8020/user/cloudera/.sparkStaging/application_1581487397453_0101/py4j-0.9-src.zip
20/03/10 09:05:25 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1281)
	at java.lang.Thread.join(Thread.java:1355)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:967)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:705)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:894)
20/03/10 09:05:25 INFO yarn.Client: Uploading resource file:/tmp/spark-2ca0f9dd-af94-4f63-9e61-a2a7b467eda5/__spark_conf__9052123311295305469.zip -> hdfs://quickstart.cloudera:8020/user/cloudera/.sparkStaging/application_1581487397453_0101/__spark_conf__9052123311295305469.zip
20/03/10 09:05:25 INFO spark.SecurityManager: Changing view acls to: cloudera
20/03/10 09:05:25 INFO spark.SecurityManager: Changing modify acls to: cloudera
20/03/10 09:05:25 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(cloudera); users with modify permissions: Set(cloudera)
20/03/10 09:05:25 INFO yarn.Client: Submitting application 101 to ResourceManager
20/03/10 09:05:25 INFO impl.YarnClientImpl: Submitted application application_1581487397453_0101
20/03/10 09:05:26 INFO yarn.Client: Application report for application_1581487397453_0101 (state: ACCEPTED)
20/03/10 09:05:26 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: root.cloudera
	 start time: 1583811325648
	 final status: UNDEFINED
	 tracking URL: http://quickstart.cloudera:8088/proxy/application_1581487397453_0101/
	 user: cloudera
20/03/10 09:05:27 INFO yarn.Client: Application report for application_1581487397453_0101 (state: ACCEPTED)
20/03/10 09:05:28 INFO yarn.Client: Application report for application_1581487397453_0101 (state: ACCEPTED)
20/03/10 09:05:29 INFO yarn.Client: Application report for application_1581487397453_0101 (state: ACCEPTED)
20/03/10 09:05:30 INFO yarn.Client: Application report for application_1581487397453_0101 (state: ACCEPTED)
20/03/10 09:05:31 INFO yarn.Client: Application report for application_1581487397453_0101 (state: ACCEPTED)
20/03/10 09:05:32 INFO yarn.Client: Application report for application_1581487397453_0101 (state: ACCEPTED)
20/03/10 09:05:33 INFO yarn.Client: Application report for application_1581487397453_0101 (state: ACCEPTED)
20/03/10 09:05:34 INFO yarn.Client: Application report for application_1581487397453_0101 (state: ACCEPTED)
20/03/10 09:05:35 INFO yarn.Client: Application report for application_1581487397453_0101 (state: ACCEPTED)
20/03/10 09:05:36 INFO yarn.Client: Application report for application_1581487397453_0101 (state: ACCEPTED)
20/03/10 09:05:37 INFO yarn.Client: Application report for application_1581487397453_0101 (state: ACCEPTED)
20/03/10 09:05:38 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null)
20/03/10 09:05:38 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> quickstart.cloudera, PROXY_URI_BASES -> http://quickstart.cloudera:8088/proxy/application_1581487397453_0101), /proxy/application_1581487397453_0101
20/03/10 09:05:38 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
20/03/10 09:05:38 INFO yarn.Client: Application report for application_1581487397453_0101 (state: ACCEPTED)
20/03/10 09:05:39 INFO yarn.Client: Application report for application_1581487397453_0101 (state: RUNNING)
20/03/10 09:05:39 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 192.168.222.174
	 ApplicationMaster RPC port: 0
	 queue: root.cloudera
	 start time: 1583811325648
	 final status: UNDEFINED
	 tracking URL: http://quickstart.cloudera:8088/proxy/application_1581487397453_0101/
	 user: cloudera
20/03/10 09:05:39 INFO cluster.YarnClientSchedulerBackend: Application application_1581487397453_0101 has started running.
20/03/10 09:05:39 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36249.
20/03/10 09:05:39 INFO netty.NettyBlockTransferService: Server created on 36249
20/03/10 09:05:39 INFO storage.BlockManagerMaster: Trying to register BlockManager
20/03/10 09:05:39 INFO storage.BlockManagerMasterEndpoint: Registering block manager 192.168.222.174:36249 with 534.5 MB RAM, BlockManagerId(driver, 192.168.222.174, 36249)
20/03/10 09:05:39 INFO storage.BlockManagerMaster: Registered BlockManager
20/03/10 09:05:48 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)
20/03/10 09:06:01 INFO text.TextRelation: Listing hdfs://quickstart.cloudera:8020/InputFiles/Spark/access_log_Aug95 on driver
20/03/10 09:06:01 INFO text.TextRelation: Listing hdfs://quickstart.cloudera:8020/InputFiles/Spark/access_log_Jul95 on driver
20/03/10 09:06:02 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (192.168.222.174:60036) with ID 1
20/03/10 09:06:03 INFO storage.BlockManagerMasterEndpoint: Registering block manager 192.168.222.174:54356 with 267.3 MB RAM, BlockManagerId(1, 192.168.222.174, 54356)
20/03/10 09:06:06 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (192.168.222.174:60038) with ID 2
20/03/10 09:06:06 INFO storage.BlockManagerMasterEndpoint: Registering block manager 192.168.222.174:51063 with 267.3 MB RAM, BlockManagerId(2, 192.168.222.174, 51063)
20/03/10 09:06:07 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 207.4 KB, free 534.3 MB)
20/03/10 09:06:07 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.6 KB, free 534.3 MB)
20/03/10 09:06:07 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.222.174:36249 (size: 24.6 KB, free: 534.5 MB)
20/03/10 09:06:07 INFO spark.SparkContext: Created broadcast 0 from cache at NativeMethodAccessorImpl.java:-2
20/03/10 09:06:08 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 212.5 KB, free 534.1 MB)
20/03/10 09:06:08 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.7 KB, free 534.1 MB)
20/03/10 09:06:08 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.222.174:36249 (size: 24.7 KB, free: 534.5 MB)
20/03/10 09:06:08 INFO spark.SparkContext: Created broadcast 1 from cache at NativeMethodAccessorImpl.java:-2
20/03/10 09:06:09 INFO mapred.FileInputFormat: Total input paths to process : 2
20/03/10 09:06:09 INFO spark.SparkContext: Starting job: describe at NativeMethodAccessorImpl.java:-2
20/03/10 09:06:09 INFO scheduler.DAGScheduler: Got job 0 (describe at NativeMethodAccessorImpl.java:-2) with 1 output partitions
20/03/10 09:06:09 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (describe at NativeMethodAccessorImpl.java:-2)
20/03/10 09:06:09 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/03/10 09:06:09 INFO scheduler.DAGScheduler: Missing parents: List()
20/03/10 09:06:09 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[11] at describe at NativeMethodAccessorImpl.java:-2), which has no missing parents
20/03/10 09:06:09 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 21.3 KB, free 534.1 MB)
20/03/10 09:06:09 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.7 KB, free 534.0 MB)
20/03/10 09:06:09 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.222.174:36249 (size: 8.7 KB, free: 534.5 MB)
20/03/10 09:06:09 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004
20/03/10 09:06:09 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[11] at describe at NativeMethodAccessorImpl.java:-2) (first 15 tasks are for partitions Vector(0))
20/03/10 09:06:09 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks
20/03/10 09:06:09 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.222.174, executor 2, partition 0, RACK_LOCAL, 2991 bytes)
20/03/10 09:06:10 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.222.174:51063 (size: 8.7 KB, free: 267.3 MB)
20/03/10 09:06:13 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.222.174:51063 (size: 24.7 KB, free: 267.2 MB)
20/03/10 09:07:05 INFO storage.BlockManagerInfo: Added rdd_4_0 in memory on 192.168.222.174:51063 (size: 38.7 MB, free: 228.5 MB)
20/03/10 09:07:21 INFO storage.BlockManagerInfo: Added rdd_4_1 in memory on 192.168.222.174:51063 (size: 9.1 MB, free: 219.5 MB)
20/03/10 09:08:01 INFO storage.BlockManagerInfo: Added rdd_4_2 in memory on 192.168.222.174:51063 (size: 35.6 MB, free: 183.9 MB)
20/03/10 09:08:26 INFO storage.BlockManagerInfo: Added rdd_4_3 in memory on 192.168.222.174:51063 (size: 19.8 MB, free: 164.1 MB)
20/03/10 09:08:27 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 137776 ms on 192.168.222.174 (executor 2) (1/1)
20/03/10 09:08:27 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/03/10 09:08:27 INFO scheduler.DAGScheduler: ResultStage 0 (describe at NativeMethodAccessorImpl.java:-2) finished in 137.799 s
20/03/10 09:08:27 INFO scheduler.DAGScheduler: Job 0 finished: describe at NativeMethodAccessorImpl.java:-2, took 138.072924 s
Content statistics of count , mean ,standard deviation , min, max : 
20/03/10 09:08:27 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.222.174:36249 in memory (size: 8.7 KB, free: 534.5 MB)
20/03/10 09:08:27 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.222.174:51063 in memory (size: 8.7 KB, free: 164.1 MB)
20/03/10 09:08:27 INFO spark.ContextCleaner: Cleaned accumulator 16
20/03/10 09:08:27 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.222.174:36249 in memory (size: 24.6 KB, free: 534.5 MB)
+-------+-----------------+
|summary|     Content_size|
+-------+-----------------+
|  count|          3461546|
|   mean|18929.20530739733|
| stddev| 73032.1220661821|
|    min|                0|
|    max|          6823936|
+-------+-----------------+

Differnt HTTP Status wise count in ascending order :
20/03/10 09:08:28 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:-2
20/03/10 09:08:28 INFO scheduler.DAGScheduler: Got job 1 (showString at NativeMethodAccessorImpl.java:-2) with 1 output partitions
20/03/10 09:08:28 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (showString at NativeMethodAccessorImpl.java:-2)
20/03/10 09:08:28 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/03/10 09:08:28 INFO scheduler.DAGScheduler: Missing parents: List()
20/03/10 09:08:28 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[19] at showString at NativeMethodAccessorImpl.java:-2), which has no missing parents
20/03/10 09:08:28 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.2 KB, free 534.3 MB)
20/03/10 09:08:28 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.1 KB, free 534.3 MB)
20/03/10 09:08:28 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.222.174:36249 (size: 8.1 KB, free: 534.5 MB)
20/03/10 09:08:28 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004
20/03/10 09:08:28 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[19] at showString at NativeMethodAccessorImpl.java:-2) (first 15 tasks are for partitions Vector(0))
20/03/10 09:08:28 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks
20/03/10 09:08:28 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.222.174, executor 1, partition 0, RACK_LOCAL, 2991 bytes)
20/03/10 09:08:29 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.222.174:54356 (size: 8.1 KB, free: 267.3 MB)
20/03/10 09:08:40 INFO scheduler.DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:-2) finished in 11.461 s
20/03/10 09:08:40 INFO scheduler.DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:-2, took 11.583588 s
20/03/10 09:08:40 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 11463 ms on 192.168.222.174 (executor 1) (1/1)
20/03/10 09:08:40 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
+------+-------+
|Status|  count|
+------+-------+
|   200|3100522|
|   302|  73015|
|   304| 266773|
|   400|      4|
|   403|    225|
|   404|  20901|
|   500|     65|
|   501|     41|
+------+-------+

Top 10 frequest hosts :
20/03/10 09:08:40 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:-2
20/03/10 09:08:40 INFO scheduler.DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:-2) with 1 output partitions
20/03/10 09:08:40 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (showString at NativeMethodAccessorImpl.java:-2)
20/03/10 09:08:40 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/03/10 09:08:40 INFO scheduler.DAGScheduler: Missing parents: List()
20/03/10 09:08:40 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[27] at showString at NativeMethodAccessorImpl.java:-2), which has no missing parents
20/03/10 09:08:40 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 19.2 KB, free 534.3 MB)
20/03/10 09:08:40 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.1 KB, free 534.2 MB)
20/03/10 09:08:40 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.222.174:36249 (size: 8.1 KB, free: 534.5 MB)
20/03/10 09:08:40 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1004
20/03/10 09:08:40 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[27] at showString at NativeMethodAccessorImpl.java:-2) (first 15 tasks are for partitions Vector(0))
20/03/10 09:08:40 INFO cluster.YarnScheduler: Adding task set 2.0 with 1 tasks
20/03/10 09:08:40 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, 192.168.222.174, executor 1, partition 0, NODE_LOCAL, 2991 bytes)
20/03/10 09:08:40 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.222.174:54356 (size: 8.1 KB, free: 267.3 MB)
20/03/10 09:08:46 INFO scheduler.DAGScheduler: ResultStage 2 (showString at NativeMethodAccessorImpl.java:-2) finished in 5.923 s
20/03/10 09:08:46 INFO scheduler.DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:-2, took 5.979078 s
20/03/10 09:08:46 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 5926 ms on 192.168.222.174 (executor 1) (1/1)
20/03/10 09:08:46 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
+--------------------+-----+
|                Host|count|
+--------------------+-----+
|piweba3y.prodigy.com|21988|
|piweba4y.prodigy.com|16437|
|piweba1y.prodigy.com|12825|
|  edams.ksc.nasa.gov|11964|
|        163.206.89.4| 9697|
|         news.ti.com| 8161|
|www-d1.proxy.aol.com| 8047|
|  alyssa.prodigy.com| 8037|
| siltb10.orl.mmc.com| 7573|
|www-a2.proxy.aol.com| 7516|
+--------------------+-----+

Top 10 error endpoints whose status is other than 200 :
20/03/10 09:08:46 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:-2
20/03/10 09:08:46 INFO scheduler.DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:-2) with 1 output partitions
20/03/10 09:08:46 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (showString at NativeMethodAccessorImpl.java:-2)
20/03/10 09:08:46 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/03/10 09:08:46 INFO scheduler.DAGScheduler: Missing parents: List()
20/03/10 09:08:46 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[36] at showString at NativeMethodAccessorImpl.java:-2), which has no missing parents
20/03/10 09:08:46 INFO storage.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 19.6 KB, free 534.2 MB)
20/03/10 09:08:46 INFO storage.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.2 KB, free 534.2 MB)
20/03/10 09:08:46 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.222.174:36249 (size: 8.2 KB, free: 534.5 MB)
20/03/10 09:08:46 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1004
20/03/10 09:08:46 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[36] at showString at NativeMethodAccessorImpl.java:-2) (first 15 tasks are for partitions Vector(0))
20/03/10 09:08:46 INFO cluster.YarnScheduler: Adding task set 3.0 with 1 tasks
20/03/10 09:08:46 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, 192.168.222.174, executor 1, partition 0, NODE_LOCAL, 2991 bytes)
20/03/10 09:08:46 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.222.174:54356 (size: 8.2 KB, free: 267.2 MB)
20/03/10 09:08:50 INFO scheduler.DAGScheduler: ResultStage 3 (showString at NativeMethodAccessorImpl.java:-2) finished in 3.848 s
20/03/10 09:08:50 INFO scheduler.DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:-2, took 3.897613 s
20/03/10 09:08:50 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 3848 ms on 192.168.222.174 (executor 1) (1/1)
20/03/10 09:08:50 INFO cluster.YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
+---------------------------------------+-----+
|Endpoint                               |count|
+---------------------------------------+-----+
|/images/NASA-logosmall.gif             |40090|
|/images/KSC-logosmall.gif              |23763|
|/images/MOSAIC-logosmall.gif           |15245|
|/images/USA-logosmall.gif              |15142|
|/images/WORLD-logosmall.gif            |14773|
|/images/ksclogo-medium.gif             |13559|
|/images/launch-logo.gif                |8806 |
|/history/apollo/images/apollo-logo1.gif|7489 |
|/                                      |6297 |
|/images/ksclogosmall.gif               |5669 |
+---------------------------------------+-----+

Count of unique number of hosts per day :
20/03/10 09:08:51 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:-2
20/03/10 09:08:51 INFO scheduler.DAGScheduler: Got job 4 (showString at NativeMethodAccessorImpl.java:-2) with 1 output partitions
20/03/10 09:08:51 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (showString at NativeMethodAccessorImpl.java:-2)
20/03/10 09:08:51 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/03/10 09:08:51 INFO scheduler.DAGScheduler: Missing parents: List()
20/03/10 09:08:51 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[47] at showString at NativeMethodAccessorImpl.java:-2), which has no missing parents
20/03/10 09:08:51 INFO storage.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 19.9 KB, free 534.2 MB)
20/03/10 09:08:51 INFO storage.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.0 KB, free 534.2 MB)
20/03/10 09:08:51 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.222.174:36249 (size: 8.0 KB, free: 534.5 MB)
20/03/10 09:08:51 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1004
20/03/10 09:08:51 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[47] at showString at NativeMethodAccessorImpl.java:-2) (first 15 tasks are for partitions Vector(0))
20/03/10 09:08:51 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks
20/03/10 09:08:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, 192.168.222.174, executor 1, partition 0, NODE_LOCAL, 3036 bytes)
20/03/10 09:08:51 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.222.174:54356 (size: 8.0 KB, free: 267.2 MB)
20/03/10 09:09:04 INFO scheduler.DAGScheduler: ResultStage 4 (showString at NativeMethodAccessorImpl.java:-2) finished in 12.664 s
20/03/10 09:09:04 INFO scheduler.DAGScheduler: Job 4 finished: showString at NativeMethodAccessorImpl.java:-2, took 12.779809 s
20/03/10 09:09:04 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 12681 ms on 192.168.222.174 (executor 1) (1/1)
20/03/10 09:09:04 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
+-----------+-----+
|Day        |count|
+-----------+-----+
|01/Aug/1995|2582 |
|03/Aug/1995|3222 |
|04/Aug/1995|4191 |
|05/Aug/1995|2502 |
|06/Aug/1995|2538 |
|07/Aug/1995|4108 |
|08/Aug/1995|4406 |
|09/Aug/1995|4317 |
|10/Aug/1995|4523 |
|11/Aug/1995|4346 |
|12/Aug/1995|2865 |
|13/Aug/1995|2650 |
|14/Aug/1995|4454 |
|15/Aug/1995|4214 |
|16/Aug/1995|4340 |
|17/Aug/1995|4385 |
|18/Aug/1995|4168 |
|19/Aug/1995|2550 |
|20/Aug/1995|2560 |
|21/Aug/1995|4135 |
+-----------+-----+
only showing top 20 rows

Hourly basis 404 error count :
20/03/10 09:09:04 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:-2
20/03/10 09:09:04 INFO scheduler.DAGScheduler: Got job 5 (showString at NativeMethodAccessorImpl.java:-2) with 1 output partitions
20/03/10 09:09:04 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (showString at NativeMethodAccessorImpl.java:-2)
20/03/10 09:09:04 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/03/10 09:09:04 INFO scheduler.DAGScheduler: Missing parents: List()
20/03/10 09:09:04 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[57] at showString at NativeMethodAccessorImpl.java:-2), which has no missing parents
20/03/10 09:09:04 INFO storage.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 19.9 KB, free 534.2 MB)
20/03/10 09:09:04 INFO storage.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 8.4 KB, free 534.2 MB)
20/03/10 09:09:04 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.222.174:36249 (size: 8.4 KB, free: 534.5 MB)
20/03/10 09:09:04 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1004
20/03/10 09:09:04 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[57] at showString at NativeMethodAccessorImpl.java:-2) (first 15 tasks are for partitions Vector(0))
20/03/10 09:09:04 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks
20/03/10 09:09:04 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, 192.168.222.174, executor 2, partition 0, NODE_LOCAL, 3036 bytes)
20/03/10 09:09:04 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.222.174:51063 (size: 8.4 KB, free: 164.1 MB)
20/03/10 09:09:07 INFO scheduler.DAGScheduler: ResultStage 5 (showString at NativeMethodAccessorImpl.java:-2) finished in 2.848 s
20/03/10 09:09:07 INFO scheduler.DAGScheduler: Job 5 finished: showString at NativeMethodAccessorImpl.java:-2, took 2.967657 s
20/03/10 09:09:07 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 2851 ms on 192.168.222.174 (executor 2) (1/1)
20/03/10 09:09:07 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool 
+----+-----+
|Hour|count|
+----+-----+
|00  |774  |
|01  |648  |
|02  |868  |
|03  |603  |
|04  |351  |
|05  |307  |
|06  |269  |
|07  |458  |
|08  |705  |
|09  |840  |
|10  |1087 |
|11  |1160 |
|12  |1308 |
|13  |1151 |
|14  |1274 |
|15  |1382 |
|16  |1181 |
|17  |1203 |
|18  |930  |
|19  |852  |
+----+-----+
only showing top 20 rows

Average number of request daily on per host per day:
20/03/10 09:09:08 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:-2
20/03/10 09:09:08 INFO scheduler.DAGScheduler: Got job 6 (showString at NativeMethodAccessorImpl.java:-2) with 1 output partitions
20/03/10 09:09:08 INFO scheduler.DAGScheduler: Final stage: ResultStage 6 (showString at NativeMethodAccessorImpl.java:-2)
20/03/10 09:09:08 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/03/10 09:09:08 INFO scheduler.DAGScheduler: Missing parents: List()
20/03/10 09:09:08 INFO scheduler.DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[85] at showString at NativeMethodAccessorImpl.java:-2), which has no missing parents
20/03/10 09:09:08 INFO storage.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 29.1 KB, free 534.1 MB)
20/03/10 09:09:08 INFO storage.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 10.9 KB, free 534.1 MB)
20/03/10 09:09:08 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.222.174:36249 (size: 10.9 KB, free: 534.5 MB)
20/03/10 09:09:08 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1004
20/03/10 09:09:08 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[85] at showString at NativeMethodAccessorImpl.java:-2) (first 15 tasks are for partitions Vector(0))
20/03/10 09:09:08 INFO cluster.YarnScheduler: Adding task set 6.0 with 1 tasks
20/03/10 09:09:08 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, 192.168.222.174, executor 1, partition 0, NODE_LOCAL, 3462 bytes)
20/03/10 09:09:08 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.222.174:54356 (size: 10.9 KB, free: 267.2 MB)
20/03/10 09:09:26 INFO scheduler.DAGScheduler: ResultStage 6 (showString at NativeMethodAccessorImpl.java:-2) finished in 17.535 s
20/03/10 09:09:26 INFO scheduler.DAGScheduler: Job 6 finished: showString at NativeMethodAccessorImpl.java:-2, took 17.624151 s
20/03/10 09:09:26 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 17537 ms on 192.168.222.174 (executor 1) (1/1)
20/03/10 09:09:26 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool 
+-----------+-----------+--------------+------------------+
|Day        |Total_Hosts|Total_Requests|Avg_Req           |
+-----------+-----------+--------------+------------------+
|01/Aug/1995|2582       |33996         |13.166537567776917|
|01/Jul/1995|5192       |64714         |12.464175654853621|
|02/Jul/1995|4859       |60265         |12.40275776908829 |
|03/Aug/1995|3222       |41388         |12.845437616387336|
|03/Jul/1995|7336       |89584         |12.211559432933479|
|04/Aug/1995|4191       |59557         |14.210689572894298|
|04/Jul/1995|5524       |70452         |12.753801593048516|
|05/Aug/1995|2502       |31893         |12.747002398081534|
|05/Jul/1995|7383       |94575         |12.809833401056482|
|06/Aug/1995|2538       |32420         |12.77383766745469 |
|06/Jul/1995|7820       |100960        |12.910485933503836|
|07/Aug/1995|4108       |57362         |13.9634858812074  |
|07/Jul/1995|6474       |87233         |13.474358974358974|
|08/Aug/1995|4406       |60157         |13.653427144802542|
|08/Jul/1995|2898       |38867         |13.411663216011043|
|09/Aug/1995|4317       |60458         |14.00463284688441 |
|09/Jul/1995|2554       |35272         |13.810493343774471|
|10/Aug/1995|4523       |61248         |13.541454786646032|
|10/Jul/1995|4464       |72859         |16.321460573476703|
|11/Aug/1995|4346       |61246         |14.092498849516797|
+-----------+-----------+--------------+------------------+
only showing top 20 rows

20/03/10 09:09:26 INFO spark.SparkContext: Invoking stop() from shutdown hook
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static/sql,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
20/03/10 09:09:26 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
20/03/10 09:09:26 INFO ui.SparkUI: Stopped Spark web UI at http://192.168.222.174:4043
20/03/10 09:09:26 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread
20/03/10 09:09:26 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
20/03/10 09:09:26 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down
20/03/10 09:09:26 INFO cluster.YarnClientSchedulerBackend: Stopped
20/03/10 09:09:26 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/03/10 09:09:26 INFO storage.MemoryStore: MemoryStore cleared
20/03/10 09:09:26 INFO storage.BlockManager: BlockManager stopped
20/03/10 09:09:26 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
20/03/10 09:09:26 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/03/10 09:09:26 INFO spark.SparkContext: Successfully stopped SparkContext
20/03/10 09:09:26 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
20/03/10 09:09:26 INFO util.ShutdownHookManager: Shutdown hook called
20/03/10 09:09:26 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-2ca0f9dd-af94-4f63-9e61-a2a7b467eda5
20/03/10 09:09:26 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-2ca0f9dd-af94-4f63-9e61-a2a7b467eda5/pyspark-5110f32f-4f5b-4719-924c-005e9d64a9df
[cloudera@quickstart spark]$ 
